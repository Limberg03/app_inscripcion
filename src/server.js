// server.js - VERSI√ìN INTEGRADA RESPETANDO TU ARQUITECTURA
const cluster = require('cluster');
const os = require('os');
const http = require('http');

// Configuraciones de clustering y optimizaci√≥n
const SERVER_CONFIG = {
  port: process.env.PORT || 3000,
  maxConnections: 2000,
  timeout: 30000,
  keepAliveTimeout: 65000,
  headersTimeout: 66000,
  maxRequestsPerSocket: 0,
  backlog: 1024,
  enableClustering: process.env.NODE_ENV === 'production' // Solo en producci√≥n
};

// Rate limiter compartido entre workers
const rateLimiter = new Map();
const RATE_LIMIT_WINDOW = 60000; // 1 minuto
const RATE_LIMIT_MAX = 100; // 100 requests por minuto por IP

const checkRateLimit = (ip) => {
  const now = Date.now();
  const windowStart = now - RATE_LIMIT_WINDOW;
  
  if (!rateLimiter.has(ip)) {
    rateLimiter.set(ip, []);
  }
  
  const requests = rateLimiter.get(ip);
  const validRequests = requests.filter(time => time > windowStart);
  
  if (validRequests.length >= RATE_LIMIT_MAX) {
    return false;
  }
  
  validRequests.push(now);
  rateLimiter.set(ip, validRequests);
  return true;
};

// Middleware de rate limiting que se integrar√° con tu app
const rateLimitMiddleware = (req, res, next) => {
  // Solo aplicar rate limiting en producci√≥n
  if (process.env.NODE_ENV !== 'production') {
    return next();
  }
  
  const ip = req.ip || req.connection.remoteAddress;
  
  if (!checkRateLimit(ip)) {
    return res.status(429).json({
      success: false,
      message: 'Rate limit exceeded',
      retryAfter: 60,
      workerId: cluster.worker ? cluster.worker.id : 'main'
    });
  }
  
  next();
};

// CLUSTERING CONDICIONAL
if (SERVER_CONFIG.enableClustering && cluster.isMaster) {
  // ================ PROCESO MAESTRO ================
  const numCPUs = Math.min(os.cpus().length, 4); // M√°ximo 4 workers
  console.log(`üöÄ Master process starting with ${numCPUs} workers`);
  console.log(`üìä Clustering enabled for production environment`);
  
  // Crear workers
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }
  
  // Manejo de workers que fallan
  cluster.on('exit', (worker, code, signal) => {
    console.log(`üíÄ Worker ${worker.process.pid} died (${signal || code}). Restarting...`);
    cluster.fork();
  });
  
  // Estad√≠sticas del cluster cada 30 segundos
  if (process.env.NODE_ENV === 'development') {
    setInterval(() => {
      const workers = Object.keys(cluster.workers).length;
      console.log(`üìä Cluster status: ${workers} workers running`);
    }, 30000);
  }
  
  // Graceful shutdown del cluster
  process.on('SIGTERM', () => {
    console.log('üõë Master process shutting down...');
    for (const id in cluster.workers) {
      cluster.workers[id].kill();
    }
  });
  
} else {
  // ================ PROCESO WORKER O DESARROLLO ================
  const startWorker = async () => {
    try {
      // Importar TU app.js existente
      const { app, initializeApp, queueService, callbackService } = require('./app');
      
      console.log(`üî• ${cluster.worker ? `Worker ${cluster.worker.id}` : 'Single process'} starting...`);
      
      // 1. EJECUTAR TU L√ìGICA DE INICIALIZACI√ìN EXISTENTE
      await initializeApp();
      console.log(`‚úÖ ${cluster.worker ? `Worker ${cluster.worker.id}` : 'App'}: Inicializaci√≥n completada`);
      
      // 2. A√ëADIR MIDDLEWARE DE OPTIMIZACI√ìN A TU APP EXISTENTE
      
      // Rate limiting solo en rutas API
      app.use('/api', rateLimitMiddleware);
      
      // Headers de optimizaci√≥n
      app.use((req, res, next) => {
        res.setHeader('Connection', 'keep-alive');
        res.setHeader('Keep-Alive', 'timeout=65');
        res.setHeader('X-Powered-By', 'Optimized-Node');
        if (cluster.worker) {
          res.setHeader('X-Worker-ID', cluster.worker.id);
        }
        next();
      });
      
      // 3. A√ëADIR RUTAS ADICIONALES DE MONITOREO
      
      // Health check optimizado
      app.get('/health', (req, res) => {
        const qService = queueService ? queueService() : null;
        const cService = callbackService ? callbackService() : null;
        
        res.status(200).json({ 
          status: 'ok', 
          timestamp: new Date().toISOString(),
          worker: cluster.worker ? cluster.worker.id : 'main',
          uptime: process.uptime(),
          services: {
            queue: qService ? 'active' : 'inactive',
            callback: cService ? 'active' : 'inactive'
          },
          memory: {
            rss: Math.round(process.memoryUsage().rss / 1024 / 1024) + 'MB',
            heapUsed: Math.round(process.memoryUsage().heapUsed / 1024 / 1024) + 'MB'
          }
        });
      });
      
      // Stats detallados
      app.get('/cluster-stats', async (req, res) => {
        const qService = queueService ? queueService() : null;
        let redisInfo = null;
        
        try {
          if (qService && typeof qService.getRedisInfo === 'function') {
            redisInfo = await qService.getRedisInfo();
          }
        } catch (error) {
          // Redis no disponible
        }
        
        res.status(200).json({
          success: true,
          worker: {
            id: cluster.worker ? cluster.worker.id : 'main',
            pid: process.pid,
            uptime: process.uptime(),
            memory: process.memoryUsage()
          },
          server: {
            nodeVersion: process.version,
            platform: process.platform,
            arch: process.arch
          },
          services: {
            redis: redisInfo ? 'connected' : 'disconnected',
            queue: qService ? 'active' : 'inactive'
          },
          rateLimiter: {
            activeIPs: rateLimiter.size,
            totalRequests: Array.from(rateLimiter.values()).reduce((acc, reqs) => acc + reqs.length, 0)
          }
        });
      });
      
      // 4. CREAR SERVIDOR HTTP OPTIMIZADO CON TU APP
      const server = http.createServer(app);
      
      // Aplicar configuraciones de rendimiento
      server.maxConnections = SERVER_CONFIG.maxConnections;
      server.timeout = SERVER_CONFIG.timeout;
      server.keepAliveTimeout = SERVER_CONFIG.keepAliveTimeout;
      server.headersTimeout = SERVER_CONFIG.headersTimeout;
      server.maxRequestsPerSocket = SERVER_CONFIG.maxRequestsPerSocket;
      
      // 5. INICIAR SERVIDOR
      server.listen(SERVER_CONFIG.port, SERVER_CONFIG.backlog, () => {
        const workerInfo = cluster.worker ? `Worker ${cluster.worker.id}` : 'Single process';
        console.log(`\nüöÄ ${workerInfo} listening on http://localhost:${SERVER_CONFIG.port}`);
        
        if (!cluster.worker || cluster.worker.id === 1) {
          // Solo mostrar una vez en clustering
          console.log(`üìä Dashboard: http://localhost:${SERVER_CONFIG.port}/public/dashboard.html`);
          console.log(`üìà Stats: http://localhost:${SERVER_CONFIG.port}/cluster-stats`);
          console.log(`üíö Health: http://localhost:${SERVER_CONFIG.port}/health`);
          console.log('üí° Los workers est√°n PAUSADOS por defecto. In√≠cialos v√≠a API desde el dashboard.\n');
        }
      });
      
      // 6. GRACEFUL SHUTDOWN INTEGRADO CON TUS SERVICIOS
      const gracefulShutdown = async (signal) => {
        console.log(`\nüîÑ ${cluster.worker ? `Worker ${cluster.worker.id}` : 'Process'} received ${signal}. Shutting down gracefully...`);
        
        server.close(async () => {
          try {
            // Usar la l√≥gica de shutdown de tu app si existe
            const qService = queueService ? queueService() : null;
            if (qService && typeof qService.shutdown === 'function') {
              await qService.shutdown();
              console.log('‚úÖ Queue service shutdown completed');
            }
            
            console.log(`‚úÖ ${cluster.worker ? `Worker ${cluster.worker.id}` : 'Process'} shutdown completed`);
            process.exit(0);
          } catch (error) {
            console.error('‚ùå Error during graceful shutdown:', error);
            process.exit(1);
          }
        });
      };
      
      // Event listeners para shutdown
      process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
      process.on('SIGINT', () => gracefulShutdown('SIGINT'));
      
      // Monitoreo de memoria en desarrollo
      if (process.env.NODE_ENV === 'development') {
        setInterval(() => {
          const mem = process.memoryUsage();
          const workerInfo = cluster.worker ? `Worker ${cluster.worker.id}` : 'Process';
          console.log(`${workerInfo} Memory: ${Math.round(mem.rss / 1024 / 1024)}MB RSS, ${Math.round(mem.heapUsed / 1024 / 1024)}MB Heap`);
        }, 120000); // Cada 2 minutos
      }
      
    } catch (error) {
      console.error(`‚ùå ${cluster.worker ? `Worker ${cluster.worker.id}` : 'Process'} failed to start:`, error);
      
      // Informaci√≥n √∫til para debugging
      if (error.message.includes('Redis') || error.code === 'ECONNREFUSED') {
        console.error('üí° SOLUCI√ìN: Aseg√∫rate de que el servidor Redis est√© en ejecuci√≥n');
        console.error('   - Docker: docker run -d -p 6379:6379 redis:alpine');
        console.error('   - Local: redis-server');
      }
      
      process.exit(1);
    }
  };
  
  // Iniciar el worker
  startWorker();
}
